{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "3a61b7b83e458b12ef92bcb36bb1978123ef214920c2173bd2b9a204e4ae1c20"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "source": [
    "## GPU 지원"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: cupy in d:\\anaconda3\\lib\\site-packages (8.3.0)\nRequirement already satisfied: fastrlock>=0.3 in d:\\anaconda3\\lib\\site-packages (from cupy) (0.6)\nRequirement already satisfied: numpy>=1.15 in d:\\anaconda3\\lib\\site-packages (from cupy) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "#!pip install cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook에서는 cupy 모듈이 인식되지 않음\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x = cp.arange(6).reshape(2, 3)\n",
    "y = np.array([1, 2, 3])\n",
    "\n",
    "# NumPy to CuPy\n",
    "a = cp.asarray(y)\n",
    "print(a)\n",
    "print(type(a))\n",
    "print(type(y))\n",
    "assert type(a) == cp.ndarray\n",
    "\n",
    "# CuPy to NumPy\n",
    "b = cp.asnumpy(x)\n",
    "print(b)\n",
    "print(type(b))\n",
    "print(type(x))\n",
    "assert type(b) == np.ndarray\n",
    "\n",
    "xp = cp.get_array_module(y)\n",
    "assert xp == np\n",
    "xp = cp.get_array_module(x)\n",
    "assert xp == cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda.py - Update"
   ]
  },
  {
   "source": [
    "### Variable/Layer/DataLoader Class Update"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    \"\"\" Update Version (Level 5-1).\n",
    "    Class Variable : np.array 값을 다루되 다른 멤버변수를 추가적인 특징으로 가져 다양한 정보를 모두 포함시키는 클래스.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    data : np.array\n",
    "        실제 연산에서 사용되는 값으로, 다양한 연산 및 정보 전달에도 사용\n",
    "    grad : int, float\n",
    "        역전파 수행 시, 현재 역전파 층에서의 gradient 값을 저장하여 다음 역전파에 전달하는 기능을 수행\n",
    "    creator : callable function\n",
    "        Variable 객체(인스턴스)를 연산하기 위한 함수가 무엇인지 저장하여 현재 객체는 creator에 들어온 함수값을 수행하기 위해 존재하는 것으로 판단하면 됨\n",
    "    generation : Variable 객체가 어느 세대(generation)에 포함되어 있는지를 표현하기 위한 변수\n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    # 재귀 방식과 반복문 방식의 경우 메모리 할당 측면에서 반복문 방식이 유리하다.\n",
    "    # 재귀 방식은 호출 시마다 메모리에 누적되나 반복문의 경우 pop을 활용해 메모리가 누적되지 않은 상태로 작업을 수월한다.\n",
    "    __init__\n",
    "        isinstance : 첫 번째 파라미터값의 타입과 두 번째 파라미터값의 동등 여부를 확인하는 함수\n",
    "        retain_grad : gradient 값(y().grad)을 유지시킬지 설정하는 변수. default = False\n",
    "        name : 차후 Variable에 이름을 달아주기 위해 설정\n",
    "        >> Update\n",
    "        : array_types라는 tuple에 모듈 type을 저장한 후 해당 타입을 init에서 체크\n",
    "    cleargrad\n",
    "        메모리 절약을 위해서 한 번 할당했던 변수를 또 다시 사용해야 할 경우 기존 메모리에 있던 Variable.grad 정보가 남아있기 때문에 할당을 해제해주어야 제대로 동작을 수행하게 된다.\n",
    "    backward\n",
    "        반복문을 이용한 역전파 코드\n",
    "        while loop 내에서 zip 함수를 활용하여 x.grad에 중복되게 값이 들어갈 경우 기존 노드에 더해지도록 만들어 x + x = 2x 라는 식을 예로 들었을 때, gradient 값이 2로 정상 출력되게 하였음\n",
    "        add_func\n",
    "            역전파 시 함수가 pop되면서 새로운 값이 들어올 때, 같은 메모리를 참조하는 경우에 중복 방지를 위해서 추가된 함수\n",
    "            이미지 결과를 보면 더 이해가 쉽기 때문에 아래 코드블럭 중 Check로 Markdown 표시를 한 곳에서 이미지를 확인하기를 추천!!!\n",
    "        weakref\n",
    "            순환 참조로 인해 생기는 메모리 누수 문제를 해결하기 위해 import된 weakref 객체에 대해 실제로 값을 출력할 때는 Variable처럼 weakref도 어떠한 기본 데이터타입을 감싸고 있는 형태이므로 기본 생성자를 통해 객체를 호출함과 동시에 output을 사용해 실제 결과값을 확인함\n",
    "        self.grad. 즉 역전파 시작 시 기존에는 ndarray 인스턴스를 받았으나 고차 미분을 가능하게 하기 위해 ndarray 인스턴스가 아닌 Variable 인스턴스를 받도록 설정\n",
    "        입력 파라미터에 create_graph 변수 추가. 역전파 1회 계산 후 역전파를 비활성 모드로 실행하게 만드는 파라미터\n",
    "        with using_config(name, value) 구문을 생성하여 역전파 설정을 통해 들여쓰기된 구문의 수행 여부를 판단\n",
    "        >> Update\n",
    "        : myPackage.cuda.get_array_module로 데이터타입 체크 후 import할 모듈 선택하는 구문 추가\n",
    "    shape, ndim, size, dtype : numpy에 기본적으로 내장되어있는 메서드를 @property 데코레이터를 활용하여 바로 호출할 수 있도록 설정\n",
    "    __len__ : data의 길이 반환\n",
    "    __repr__ : print로 객체를 표현할 때 return할 값을 설정\n",
    "    __mul__ : 다른 객체 또는 데이터타입과의 multiply 기능 지원\n",
    "    reshape(self, *shape) : 만약에 가변인자로 들어오는 shape 값이 1개인 경우 그 값의 instance가 tuple or list일 때 shape[0]를 shape로 지정하고 그 외의 경우에는 myPackage.functions.reshape 함수를 사용하여 *shape의 값을 그대로 반영하여 reshape 진행\n",
    "    transpose : Variable 인스턴스에서 transpose 메서드를 호출했을 때, myPackage.functions에서 transpose 함수를 바로 호출할 수 있도록 설정\n",
    "    T : transpose를 바로 실행할 수 있도록 만든 @property function. @property 데코레이터를 사용하여 self 객체를 instance 변수로 바로 사용할 수 있도록 설정하였음\n",
    "    sum : myPackage.functions.sum 함수를 호출하여 Variable 인스턴스에서 바로 sum 함수를 호출할 수 있도록 설정\n",
    "    >> Update\n",
    "        to_gpu & to_cpu: Variable 데이터를 GPU or CPU로 전송해주는 기능을 수행하는 메서드\n",
    "    \"\"\"\n",
    "    def __init__(self, data, name = None):\n",
    "        if data is not None:\n",
    "            if not isinstance(data, array_types):\n",
    "                raise TypeError(f'{type(data)} is not supported.')\n",
    "\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.grad = None\n",
    "        self.creator = None\n",
    "        self.generation = 0\n",
    "\n",
    "    def cleargrad(self):\n",
    "        self.grad = None\n",
    "\n",
    "    def set_creator(self, func):\n",
    "        self.creator = func\n",
    "        self.generation = func.generation + 1\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "    @property\n",
    "    def ndim(self):\n",
    "        return self.data.ndim\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.data.size\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.data.dtype\n",
    "\n",
    "    @property\n",
    "    def T(self):\n",
    "        return myPackage.functions.transpose(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.data is None:\n",
    "            return \"variable(None)\"\n",
    "        p = str(self.data).replace('\\n', '\\n' + ' ' * 9)\n",
    "        return f\"variable({p})\"\n",
    "\n",
    "    def reshape(self, *shape):\n",
    "        if len(shape) == 1 and isinstance(shape[0], (tuple, list)):\n",
    "            shape = shape[0]\n",
    "        return myPackage.functions.reshape(self, shape)\n",
    "\n",
    "    def transpose(self):\n",
    "        return myPackage.functions.transpose(self)\n",
    "\n",
    "    def sum(self, axis=None, keepdims=False):\n",
    "        return myPackage.functions.sum(self, axis, keepdims)\n",
    "\n",
    "    def backward(self, retain_grad = False, create_graph = False):\n",
    "        if self.grad is None:\n",
    "            xp = myPackage.cuda.get_array_module(self.data)\n",
    "            self.grad = Variable(xp.ones_like(self.data))\n",
    "\n",
    "        funcs = []\n",
    "        seen_set = set()\n",
    "\n",
    "        def add_func(f):\n",
    "            if f not in seen_set:\n",
    "                funcs.append(f)\n",
    "                seen_set.add(f)\n",
    "                funcs.sort(key = lambda x: x.generation)\n",
    "\n",
    "        add_func(self.creator)\n",
    "\n",
    "        while funcs:\n",
    "            f = funcs.pop()\n",
    "            gys = [output().grad for output in f.outputs]\n",
    "\n",
    "            with using_config('enable_backprop', create_graph):\n",
    "                gxs = f.backward(*gys)\n",
    "                if not isinstance(gxs, tuple):\n",
    "                    gxs = (gxs,)\n",
    "\n",
    "                for x, gx in zip(f.inputs, gxs):\n",
    "                    if x.grad is None:\n",
    "                        x.grad = gx\n",
    "                    else:\n",
    "                        x.grad = x.grad + gx\n",
    "\n",
    "                    if x.creator is not None:\n",
    "                        add_func(x.creator)\n",
    "            \n",
    "            if not retain_grad:\n",
    "                for y in f.outputs:\n",
    "                    y().grad = None\n",
    "\n",
    "    def to_cpu(self):\n",
    "        if self.data is not None:\n",
    "            self.data = myPackage.cuda.as_numpy(self.data)\n",
    "\n",
    "    def to_gpu(self):\n",
    "        if self.data is not None:\n",
    "            self.data = myPackage.cuda.as_cupy(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"\n",
    "    Layer class\n",
    "    -----------\n",
    "    input, hidden, output layer에 대한 기반클래스\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    name: Layer's name.\n",
    "    value: Layer's value is put in name's attritube.\n",
    "    inputs: This parameter means layer's input data.\n",
    "\n",
    "    Method\n",
    "    ------\n",
    "    __setattr__: Get parameter(name, value) and check a value's type in Parameter instance. Then, set attribute value about name.\n",
    "    __call__: Make callable function instance with inputs value(get variable argument)(This method use weakref.ref for help to circular reference.).\n",
    "    forward: It will be necessary method from derived class.\n",
    "    params: Yield a layer instances value using iterator.\n",
    "    cleargrad: Clear all value's gradient.\n",
    "    >> Update\n",
    "        to_gpu & to_cpu: Variable 데이터를 GPU or CPU로 전송해주는 기능을 수행하는 메서드\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._params = set()\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if isinstance(value, (Parameter, Layer)): # Layer 추가\n",
    "            self._params.add(name)\n",
    "        super().__setattr__(name, value)\n",
    "\n",
    "    def __call__(self, *inputs):\n",
    "        outputs = self.forward(*inputs)\n",
    "        if not isinstance(outputs, tuple):\n",
    "            outputs = (outputs,)\n",
    "        self.inputs = [weakref.ref(x) for x in inputs]\n",
    "        self.outputs = [weakref.ref(y) for y in outputs]\n",
    "        return outputs if len(outputs) > 1 else outputs[0]\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def params(self):\n",
    "        for name in self._params:\n",
    "            obj = self.__dict__[name]\n",
    "\n",
    "            if isinstance(obj, Layer): # Layer에서 매개변수 꺼내기\n",
    "                yield from obj.params()\n",
    "            else:\n",
    "                yield obj\n",
    "        \n",
    "    def cleargrads(self):\n",
    "        for param in self.params():\n",
    "            param.cleargrad()\n",
    "\n",
    "    def to_cpu(self):\n",
    "        for param in self.params():\n",
    "            param.to_cpu()\n",
    "\n",
    "    def to_gpu(self):\n",
    "        for param in self.params():\n",
    "            param.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    DataLoader class\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    dataset : Dataset 인터페이스를 만족하는 인스턴스(이 말인 즉슨, __getitem__ & __len__ 메서드를 구현한 클래스로부터 생성된 인스턴스를 의미)\n",
    "    batch_size : 배치 크기\n",
    "    shuffle : 에포크별로 데이터셋을 뒤섞을지 여부\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, batch_size, shuffle=True, gpu=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.data_size = len(dataset)\n",
    "        self.max_iter = math.ceil(self.data_size / batch_size)\n",
    "        self.gpu = gpu # Update\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.iteration = 0\n",
    "        if self.shuffle:\n",
    "            self.index = np.random.permutation(len(self.dataset))\n",
    "        else:\n",
    "            self.index = np.arange(len(self.dataset))\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.iteration >= self.max_iter:\n",
    "            self.reset()\n",
    "            raise StopIteration\n",
    "\n",
    "        i, batch_size = self.iteration, self.batch_size\n",
    "        batch_index = self.index[i * batch_size:(i + 1) * batch_size]\n",
    "        batch = [self.dataset[i] for i in batch_index]\n",
    "        # x = np.array([example[0] for example in batch])\n",
    "        # t = np.array([example[1] for example in batch])\n",
    "\n",
    "        # Update\n",
    "        xp = cuda.cupy if self.gpu else np\n",
    "        x = xp.array([example[0] for example in batch])\n",
    "        t = xp.array([example[1] for example in batch])\n",
    "\n",
    "        self.iteration += 1\n",
    "\n",
    "        return x, t\n",
    "\n",
    "    def next(self):\n",
    "        return self.__next__()\n",
    "\n",
    "\n",
    "    def to_cpu(self);\n",
    "        self.gpu = False\n",
    "\n",
    "    def to_gpu(self):\n",
    "        self.gpu = True"
   ]
  },
  {
   "source": [
    "## 함수 추가 구현"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}