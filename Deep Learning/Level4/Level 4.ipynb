{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 텐서(원소별 계산)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "__file__ in globals\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import myPackage.functions as F\n",
    "from myPackage import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable(0.8414709848078965) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "x = Variable(np.array(1.))\n",
    "y = F.sin(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([[ 0.84147098  0.90929743  0.14112001]\n          [-0.7568025  -0.95892427 -0.2794155 ]]) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "temp = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "x = Variable(temp)\n",
    "y = F.sin(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([[11 22 33]\n          [44 55 66]]) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "temp1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "temp2 = np.array([[10, 20, 30], [40, 50, 60]])\n",
    "x = Variable(temp1)\n",
    "c = Variable(temp2)\n",
    "y = x + c\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "## 텐서 + 역전파\n",
    "### 39장의 합계 함수가 포함된 장으로, sum 함수가 정의된 다음 다음의 코드블럭들을 실행할 수 있음"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable(231) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "x = Variable(temp1)\n",
    "c = Variable(temp2)\n",
    "t = x + c\n",
    "y = F.sum(t)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable(1) from class's __repr__\nvariable([[1 1 1]\n          [1 1 1]]) from class's __repr__\nvariable([[1 1 1]\n          [1 1 1]]) from class's __repr__\nvariable([[1 1 1]\n          [1 1 1]]) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "y.backward(retain_grad=True)\n",
    "print(y.grad) # Variable(1)\n",
    "print(t.grad) # Variable([[1 1 1], [1 1 1]])\n",
    "print(x.grad) # Variable([[1 1 1], [1 1 1]])\n",
    "print(c.grad) # Variable([[1 1 1], [1 1 1]])"
   ]
  },
  {
   "source": [
    "## myPackage.functions에 정의된 reshape 함수 사용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myPackage.functions에 update된 클래스\n",
    "class Reshape(Function):\n",
    "    \"\"\"\n",
    "    Reshape Class\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    __inif__ : Get parameter(shape) means ndarray.shape and save that.\n",
    "    forward : Work forward propagation with parameter(x) is Variable class's instance. This methods's goal is save the x's shape and change the shape by self.shape.\n",
    "    backward : Work backward propagation with parameter(gy) is Variable class's instance (come from previous layer having Function.outputs.grad).\n",
    "    \"\"\"\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        y = x.reshape(self.shape)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        return reshape(gy, self.x_shape)\n",
    "\n",
    "def reshape(x, shape):\n",
    "    \"\"\"\n",
    "    Def reshape\n",
    "\n",
    "    Explanation\n",
    "    -----------\n",
    "    Get parameter(shape) is ndarray.shape and reshape parameter(x)'s shape from parameter(shape).\n",
    "    \"\"\"\n",
    "    if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "    return Reshape(shape)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import myPackage.functions as F\n",
    "from myPackage import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([[1 1 1]\n          [1 1 1]]) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "temp = np.arange(1, 7).reshape(2, 3)\n",
    "x = Variable(temp)\n",
    "y = F.reshape(x, (6,))\n",
    "y.backward(retain_grad=True)\n",
    "print(x.grad)"
   ]
  },
  {
   "source": [
    "## Variable에서 reshape 사용하기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[0.29796314 0.46905022 0.5587009 ]\n  [0.35107913 0.95100032 0.35477522]]]\n[[0.29796314 0.46905022 0.5587009 ]\n [0.35107913 0.95100032 0.35477522]]\n[[0.29796314 0.46905022 0.5587009 ]\n [0.35107913 0.95100032 0.35477522]]\n[[0.29796314 0.46905022 0.5587009 ]\n [0.35107913 0.95100032 0.35477522]]\n"
     ]
    }
   ],
   "source": [
    "# np.reshape 사용 방식\n",
    "x = np.random.rand(1, 2, 3) # x.shape = (1, 2, 3)\n",
    "print(x)\n",
    "\n",
    "y1 = x.reshape((2, 3)) # tuple\n",
    "print(y1)\n",
    "y2 = x.reshape([2, 3]) # list\n",
    "print(y2)\n",
    "y3 = x.reshape(2, 3) # row, col\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import myPackage # update\n",
    "\n",
    "class Variable:\n",
    "    \"\"\" Update Version (Level 4-1).\n",
    "    Class Variable : np.array 값을 다루되 다른 멤버변수를 추가적인 특징으로 가져 다양한 정보를 모두 포함시키는 클래스.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    data : np.array\n",
    "        실제 연산에서 사용되는 값으로, 다양한 연산 및 정보 전달에도 사용\n",
    "    grad : int, float\n",
    "        역전파 수행 시, 현재 역전파 층에서의 gradient 값을 저장하여 다음 역전파에 전달하는 기능을 수행\n",
    "    creator : callable function\n",
    "        Variable 객체(인스턴스)를 연산하기 위한 함수가 무엇인지 저장하여 현재 객체는 creator에 들어온 함수값을 수행하기 위해 존재하는 것으로 판단하면 됨\n",
    "    generation : Variable 객체가 어느 세대(generation)에 포함되어 있는지를 표현하기 위한 변수\n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    # 재귀 방식과 반복문 방식의 경우 메모리 할당 측면에서 반복문 방식이 유리하다.\n",
    "    # 재귀 방식은 호출 시마다 메모리에 누적되나 반복문의 경우 pop을 활용해 메모리가 누적되지 않은 상태로 작업을 수월한다.\n",
    "    __init__\n",
    "        isinstance : 첫 번째 파라미터값의 타입과 두 번째 파라미터값의 동등 여부를 확인하는 함수\n",
    "        retain_grad : gradient 값(y().grad)을 유지시킬지 설정하는 변수. default = False\n",
    "        name : 차후 Variable에 이름을 달아주기 위해 설정\n",
    "    cleargrad\n",
    "        메모리 절약을 위해서 한 번 할당했던 변수를 또 다시 사용해야 할 경우 기존 메모리에 있던 Variable.grad 정보가 남아있기 때문에 할당을 해제해주어야 제대로 동작을 수행하게 된다.\n",
    "    backward\n",
    "        반복문을 이용한 역전파 코드\n",
    "        while loop 내에서 zip 함수를 활용하여 x.grad에 중복되게 값이 들어갈 경우 기존 노드에 더해지도록 만들어 x + x = 2x 라는 식을 예로 들었을 때, gradient 값이 2로 정상 출력되게 하였음\n",
    "        add_func\n",
    "            역전파 시 함수가 pop되면서 새로운 값이 들어올 때, 같은 메모리를 참조하는 경우에 중복 방지를 위해서 추가된 함수\n",
    "            이미지 결과를 보면 더 이해가 쉽기 때문에 아래 코드블럭 중 Check로 Markdown 표시를 한 곳에서 이미지를 확인하기를 추천!!!\n",
    "        weakref\n",
    "            순환 참조로 인해 생기는 메모리 누수 문제를 해결하기 위해 import된 weakref 객체에 대해 실제로 값을 출력할 때는 Variable처럼 weakref도 어떠한 기본 데이터타입을 감싸고 있는 형태이므로 기본 생성자를 통해 객체를 호출함과 동시에 output을 사용해 실제 결과값을 확인함\n",
    "        self.grad. 즉 역전파 시작 시 기존에는 ndarray 인스턴스를 받았으나 고차 미분을 가능하게 하기 위해 ndarray 인스턴스가 아닌 Variable 인스턴스를 받도록 설정\n",
    "        입력 파라미터에 create_graph 변수 추가. 역전파 1회 계산 후 역전파를 비활성 모드로 실행하게 만드는 파라미터\n",
    "        with using_config(name, value) 구문을 생성하여 역전파 설정을 통해 들여쓰기된 구문의 수행 여부를 판단\n",
    "    shape, ndim, size, dtype : numpy에 기본적으로 내장되어있는 메서드를 @property 데코레이터를 활용하여 바로 호출할 수 있도록 설정\n",
    "    __len__ : data의 길이 반환\n",
    "    __repr__ : print로 객체를 표현할 때 return할 값을 설정\n",
    "    __mul__ : 다른 객체 또는 데이터타입과의 multiply 기능 지원\n",
    "    >> Update\n",
    "        reshape(self, *shape) : 만약에 가변인자로 들어오는 shape 값이 1개인 경우 그 값의 instance가 tuple or list일 때 shape[0]를 shape로 지정하고 그 외의 경우에는 myPackage.functions.reshape 함수를 사용하여 *shape의 값을 그대로 반영하여 reshape 진행\n",
    "    \"\"\"\n",
    "    def __init__(self, data, name = None):\n",
    "        if data is not None:\n",
    "            if not isinstance(data, np.ndarray):\n",
    "                raise TypeError(f'{type(data)} is not supported.')\n",
    "\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.grad = None\n",
    "        self.creator = None\n",
    "        self.generation = 0\n",
    "\n",
    "    def cleargrad(self):\n",
    "        self.grad = None\n",
    "\n",
    "    def set_creator(self, func):\n",
    "        self.creator = func\n",
    "        self.generation = func.generation + 1\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "    @property\n",
    "    def ndim(self):\n",
    "        return self.data.ndim\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.data.size\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.data.dtype\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.data is None:\n",
    "            return \"variable(None)\"\n",
    "        p = str(self.data).replace('\\n', '\\n' + ' ' * 9)\n",
    "        return f\"variable({p}) from class's __repr__\"\n",
    "\n",
    "    def reshape(self, *shape):\n",
    "        if len(shape) == 1 and isinstance(shape[0], (tuple, list)):\n",
    "            shape = shape[0]\n",
    "        return myPackage.functions.reshape(self, shape)\n",
    "\n",
    "    def backward(self, retain_grad = False, create_graph = False):\n",
    "        if self.grad is None:\n",
    "            self.grad = Variable(np.ones_like(self.data))\n",
    "\n",
    "        funcs = []\n",
    "        seen_set = set()\n",
    "\n",
    "        def add_func(f):\n",
    "            if f not in seen_set:\n",
    "                funcs.append(f)\n",
    "                seen_set.add(f)\n",
    "                funcs.sort(key = lambda x: x.generation)\n",
    "\n",
    "        add_func(self.creator)\n",
    "\n",
    "        while funcs:\n",
    "            f = funcs.pop()\n",
    "            gys = [output().grad for output in f.outputs]\n",
    "\n",
    "            with using_config('enable_backprop', create_graph):\n",
    "                gxs = f.backward(*gys)\n",
    "                if not isinstance(gxs, tuple):\n",
    "                    gxs = (gxs,)\n",
    "\n",
    "                for x, gx in zip(f.inputs, gxs):\n",
    "                    if x.grad is None:\n",
    "                        x.grad = gx\n",
    "                    else:\n",
    "                        x.grad = x.grad + gx\n",
    "\n",
    "                    if x.creator is not None:\n",
    "                        add_func(x.creator)\n",
    "            \n",
    "            if not retain_grad:\n",
    "                for y in f.outputs:\n",
    "                    y().grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(np.random.randn(1, 2, 3))\n",
    "y = x.reshape((2, 3))\n",
    "y = x.reshape(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "variable([[-0.70855515  1.5145279  -0.25885624]\n",
       "          [ 0.71299628 -0.5526742   0.37114441]]) from class's __repr__"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "source": [
    "## 행렬의 전치"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 4]\n [2 5]\n [3 6]]\n"
     ]
    }
   ],
   "source": [
    "# numpy 예제\n",
    "x = np.array(np.arange(1, 7).reshape(2, 3))\n",
    "y = np.transpose(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myPackage.functions에 update된 중간 단계의 Transpose 클래스\n",
    "class Transpose(Function):\n",
    "    def forward(self, x):\n",
    "        y = np.transpose(x)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        gx = transpose(gy)\n",
    "        return gx\n",
    "\n",
    "def transpose(x):\n",
    "    return Transpose()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([[1 1 1]\n          [1 1 1]]) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "temp = np.arange(1, 7).reshape(2, 3)\n",
    "x = Variable(temp)\n",
    "y = F.transpose(x)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    \"\"\" Update Version (Level 4-2).\n",
    "    Class Variable : np.array 값을 다루되 다른 멤버변수를 추가적인 특징으로 가져 다양한 정보를 모두 포함시키는 클래스.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    data : np.array\n",
    "        실제 연산에서 사용되는 값으로, 다양한 연산 및 정보 전달에도 사용\n",
    "    grad : int, float\n",
    "        역전파 수행 시, 현재 역전파 층에서의 gradient 값을 저장하여 다음 역전파에 전달하는 기능을 수행\n",
    "    creator : callable function\n",
    "        Variable 객체(인스턴스)를 연산하기 위한 함수가 무엇인지 저장하여 현재 객체는 creator에 들어온 함수값을 수행하기 위해 존재하는 것으로 판단하면 됨\n",
    "    generation : Variable 객체가 어느 세대(generation)에 포함되어 있는지를 표현하기 위한 변수\n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    # 재귀 방식과 반복문 방식의 경우 메모리 할당 측면에서 반복문 방식이 유리하다.\n",
    "    # 재귀 방식은 호출 시마다 메모리에 누적되나 반복문의 경우 pop을 활용해 메모리가 누적되지 않은 상태로 작업을 수월한다.\n",
    "    __init__\n",
    "        isinstance : 첫 번째 파라미터값의 타입과 두 번째 파라미터값의 동등 여부를 확인하는 함수\n",
    "        retain_grad : gradient 값(y().grad)을 유지시킬지 설정하는 변수. default = False\n",
    "        name : 차후 Variable에 이름을 달아주기 위해 설정\n",
    "    cleargrad\n",
    "        메모리 절약을 위해서 한 번 할당했던 변수를 또 다시 사용해야 할 경우 기존 메모리에 있던 Variable.grad 정보가 남아있기 때문에 할당을 해제해주어야 제대로 동작을 수행하게 된다.\n",
    "    backward\n",
    "        반복문을 이용한 역전파 코드\n",
    "        while loop 내에서 zip 함수를 활용하여 x.grad에 중복되게 값이 들어갈 경우 기존 노드에 더해지도록 만들어 x + x = 2x 라는 식을 예로 들었을 때, gradient 값이 2로 정상 출력되게 하였음\n",
    "        add_func\n",
    "            역전파 시 함수가 pop되면서 새로운 값이 들어올 때, 같은 메모리를 참조하는 경우에 중복 방지를 위해서 추가된 함수\n",
    "            이미지 결과를 보면 더 이해가 쉽기 때문에 아래 코드블럭 중 Check로 Markdown 표시를 한 곳에서 이미지를 확인하기를 추천!!!\n",
    "        weakref\n",
    "            순환 참조로 인해 생기는 메모리 누수 문제를 해결하기 위해 import된 weakref 객체에 대해 실제로 값을 출력할 때는 Variable처럼 weakref도 어떠한 기본 데이터타입을 감싸고 있는 형태이므로 기본 생성자를 통해 객체를 호출함과 동시에 output을 사용해 실제 결과값을 확인함\n",
    "        self.grad. 즉 역전파 시작 시 기존에는 ndarray 인스턴스를 받았으나 고차 미분을 가능하게 하기 위해 ndarray 인스턴스가 아닌 Variable 인스턴스를 받도록 설정\n",
    "        입력 파라미터에 create_graph 변수 추가. 역전파 1회 계산 후 역전파를 비활성 모드로 실행하게 만드는 파라미터\n",
    "        with using_config(name, value) 구문을 생성하여 역전파 설정을 통해 들여쓰기된 구문의 수행 여부를 판단\n",
    "    shape, ndim, size, dtype : numpy에 기본적으로 내장되어있는 메서드를 @property 데코레이터를 활용하여 바로 호출할 수 있도록 설정\n",
    "    __len__ : data의 길이 반환\n",
    "    __repr__ : print로 객체를 표현할 때 return할 값을 설정\n",
    "    __mul__ : 다른 객체 또는 데이터타입과의 multiply 기능 지원\n",
    "    reshape(self, *shape) : 만약에 가변인자로 들어오는 shape 값이 1개인 경우 그 값의 instance가 tuple or list일 때 shape[0]를 shape로 지정하고 그 외의 경우에는 myPackage.functions.reshape 함수를 사용하여 *shape의 값을 그대로 반영하여 reshape 진행\n",
    "    >> Update\n",
    "        transpose : Variable 인스턴스에서 transpose 메서드를 호출했을 때, myPackage.functions에서 transpose 함수를 바로 호출할 수 있도록 설정\n",
    "        T : transpose를 바로 실행할 수 있도록 만든 @property function. @property 데코레이터를 사용하여 self 객체를 instance 변수로 바로 사용할 수 있도록 설정하였음\n",
    "    \"\"\"\n",
    "    def __init__(self, data, name = None):\n",
    "        if data is not None:\n",
    "            if not isinstance(data, np.ndarray):\n",
    "                raise TypeError(f'{type(data)} is not supported.')\n",
    "\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.grad = None\n",
    "        self.creator = None\n",
    "        self.generation = 0\n",
    "\n",
    "    def cleargrad(self):\n",
    "        self.grad = None\n",
    "\n",
    "    def set_creator(self, func):\n",
    "        self.creator = func\n",
    "        self.generation = func.generation + 1\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "    @property\n",
    "    def ndim(self):\n",
    "        return self.data.ndim\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.data.size\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.data.dtype\n",
    "\n",
    "    @property\n",
    "    def T(self):\n",
    "        return myPackage.functions.transpose(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.data is None:\n",
    "            return \"variable(None)\"\n",
    "        p = str(self.data).replace('\\n', '\\n' + ' ' * 9)\n",
    "        return f\"variable({p}) from class's __repr__\"\n",
    "\n",
    "    def reshape(self, *shape):\n",
    "        if len(shape) == 1 and isinstance(shape[0], (tuple, list)):\n",
    "            shape = shape[0]\n",
    "        return myPackage.functions.reshape(self, shape)\n",
    "\n",
    "    def transpose(self):\n",
    "        return myPackage.functions.transpose(self)\n",
    "\n",
    "    def backward(self, retain_grad = False, create_graph = False):\n",
    "        if self.grad is None:\n",
    "            self.grad = Variable(np.ones_like(self.data))\n",
    "\n",
    "        funcs = []\n",
    "        seen_set = set()\n",
    "\n",
    "        def add_func(f):\n",
    "            if f not in seen_set:\n",
    "                funcs.append(f)\n",
    "                seen_set.add(f)\n",
    "                funcs.sort(key = lambda x: x.generation)\n",
    "\n",
    "        add_func(self.creator)\n",
    "\n",
    "        while funcs:\n",
    "            f = funcs.pop()\n",
    "            gys = [output().grad for output in f.outputs]\n",
    "\n",
    "            with using_config('enable_backprop', create_graph):\n",
    "                gxs = f.backward(*gys)\n",
    "                if not isinstance(gxs, tuple):\n",
    "                    gxs = (gxs,)\n",
    "\n",
    "                for x, gx in zip(f.inputs, gxs):\n",
    "                    if x.grad is None:\n",
    "                        x.grad = gx\n",
    "                    else:\n",
    "                        x.grad = x.grad + gx\n",
    "\n",
    "                    if x.creator is not None:\n",
    "                        add_func(x.creator)\n",
    "            \n",
    "            if not retain_grad:\n",
    "                for y in f.outputs:\n",
    "                    y().grad = None"
   ]
  },
  {
   "source": [
    "## (보충) 실제 transpose 함수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 축의 데이터 순서 변경\n",
    "A, B, C, D = 1, 2, 3, 4\n",
    "x = np.random.rand(A, B, C, D)\n",
    "y = x.transpose(1, 0, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myPackage.functions에 update된 최종 Trnaspose 클래스\n",
    "class Transpose(Function):\n",
    "    def __init__(self, axes=None):\n",
    "        self.axes = axes\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x.transpose(self.axes)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        if self.axes is None:\n",
    "            return transpose(gy)\n",
    "        \n",
    "        axes_len = len(self.axes)\n",
    "        inv_axes = tuple(np.argsort([ax % axes_len for ax in self.axes]))\n",
    "        return transpose(gy, inv_axes)\n",
    "\n",
    "def transpose(x, axes=None):\n",
    "    return Transpose(axes)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(np.random.rand(2, 3))\n",
    "y = x.transpose()\n",
    "y = x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "variable([[0.83565085 0.49163507]\n",
       "          [0.66753849 0.44648439]\n",
       "          [0.46673935 0.52092064]]) from class's __repr__"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "source": [
    "## 합계 함수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sum(Function):\n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        y = x.sum()\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        gx = broadcast_to(gy, self.x_shape)\n",
    "        return gx\n",
    "\n",
    "def sum(x):\n",
    "    return Sum()(x)"
   ]
  },
  {
   "source": [
    "### 40장의 합계 함수가 포함된 장으로, broadcast_to 함수가 정의된 다음 다음의 코드블럭들을 실행할 수 있음"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable(21) from class's __repr__\nvariable([1 1 1 1 1 1]) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "# Case 1: vector\n",
    "x = Variable(np.array([1, 2, 3, 4, 5, 6]))\n",
    "y = F.sum(x)\n",
    "y.backward()\n",
    "print(y) # Variable(21)\n",
    "print(x.grad) # Variable([1 1 1 1 1 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable(21) from class's __repr__\nvariable([[1 1 1]\n          [1 1 1]]) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "# Case 2: matrix\n",
    "x = Variable(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "y = F.sum(x)\n",
    "y.backward()\n",
    "print(y) # Variable(21)\n",
    "print(x.grad) # Variable([[1 1 1], [1 1 1]])"
   ]
  },
  {
   "source": [
    "## axis, keepdims (in numpy.sum)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5 7 9]\n(2, 3)  ->  (3,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "y = np.sum(x, axis = 0)\n",
    "print(y)\n",
    "print(x.shape, ' -> ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 3, 3)\n[ 6 15 24]\n(1, 3, 3)  ->  (3,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "print(x.shape)\n",
    "y = np.sum(x, axis = (0, 2))\n",
    "print(y)\n",
    "print(x.shape, ' -> ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[21]]\n(1, 1)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "y = np.sum(x, keepdims=True)\n",
    "print(y)\n",
    "print(y.shape)"
   ]
  },
  {
   "source": [
    "## 합계 클래스 및 함수(Sum, sum) 수정"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sum(Function):\n",
    "    def __init__(self, axis, keepdims):\n",
    "        self.axis = axis\n",
    "        self.keepdims = keepdims\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        y = x.sum(axis=self.axis, keepdims=self.keepdims)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        gy = utils.reshape_sum_backward(gy, self.x_shape, self.axis, self.keepdims)\n",
    "        gx = broadcast_to(gy, self.x_shape)\n",
    "        return gx\n",
    "\n",
    "def sum(x, axis=None, keepdims=False):\n",
    "    return Sum(axis, keepdims)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myPackage.utils.py에 update된 function\n",
    "\n",
    "def reshape_sum_backward(gy, x_shape, axis, keepdims):\n",
    "    \"\"\"Reshape gradient appropriately for myPackage.functions.sum's backward.\n",
    "    Args:\n",
    "        gy (myPackage.Variable): Gradient variable from the output by backprop.\n",
    "        x_shape (tuple): Shape used at sum function's forward.\n",
    "        axis (None or int or tuple of ints): Axis used at sum function's\n",
    "            forward.\n",
    "        keepdims (bool): Keepdims used at sum function's forward.\n",
    "    Returns:\n",
    "        myPackage.Variable: Gradient variable which is reshaped appropriately\n",
    "    \"\"\"\n",
    "    ndim = len(x_shape)\n",
    "    tupled_axis = axis\n",
    "    if axis is None:\n",
    "        tupled_axis = None\n",
    "    elif not isinstance(axis, tuple):\n",
    "        tupled_axis = (axis,)\n",
    "\n",
    "    if not (ndim == 0 or tupled_axis is None or keepdims):\n",
    "        actual_axis = [a if a >= 0 else a + ndim for a in tupled_axis]\n",
    "        shape = list(gy.shape)\n",
    "        for a in sorted(actual_axis):\n",
    "            shape.insert(a, 1)\n",
    "    else:\n",
    "        shape = gy.shape\n",
    "\n",
    "    gy = gy.reshape(shape)  # reshape\n",
    "    return gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    \"\"\" Update Version (Level 4-3).\n",
    "    Class Variable : np.array 값을 다루되 다른 멤버변수를 추가적인 특징으로 가져 다양한 정보를 모두 포함시키는 클래스.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    data : np.array\n",
    "        실제 연산에서 사용되는 값으로, 다양한 연산 및 정보 전달에도 사용\n",
    "    grad : int, float\n",
    "        역전파 수행 시, 현재 역전파 층에서의 gradient 값을 저장하여 다음 역전파에 전달하는 기능을 수행\n",
    "    creator : callable function\n",
    "        Variable 객체(인스턴스)를 연산하기 위한 함수가 무엇인지 저장하여 현재 객체는 creator에 들어온 함수값을 수행하기 위해 존재하는 것으로 판단하면 됨\n",
    "    generation : Variable 객체가 어느 세대(generation)에 포함되어 있는지를 표현하기 위한 변수\n",
    "\n",
    "    Functions\n",
    "    ---------\n",
    "    # 재귀 방식과 반복문 방식의 경우 메모리 할당 측면에서 반복문 방식이 유리하다.\n",
    "    # 재귀 방식은 호출 시마다 메모리에 누적되나 반복문의 경우 pop을 활용해 메모리가 누적되지 않은 상태로 작업을 수월한다.\n",
    "    __init__\n",
    "        isinstance : 첫 번째 파라미터값의 타입과 두 번째 파라미터값의 동등 여부를 확인하는 함수\n",
    "        retain_grad : gradient 값(y().grad)을 유지시킬지 설정하는 변수. default = False\n",
    "        name : 차후 Variable에 이름을 달아주기 위해 설정\n",
    "    cleargrad\n",
    "        메모리 절약을 위해서 한 번 할당했던 변수를 또 다시 사용해야 할 경우 기존 메모리에 있던 Variable.grad 정보가 남아있기 때문에 할당을 해제해주어야 제대로 동작을 수행하게 된다.\n",
    "    backward\n",
    "        반복문을 이용한 역전파 코드\n",
    "        while loop 내에서 zip 함수를 활용하여 x.grad에 중복되게 값이 들어갈 경우 기존 노드에 더해지도록 만들어 x + x = 2x 라는 식을 예로 들었을 때, gradient 값이 2로 정상 출력되게 하였음\n",
    "        add_func\n",
    "            역전파 시 함수가 pop되면서 새로운 값이 들어올 때, 같은 메모리를 참조하는 경우에 중복 방지를 위해서 추가된 함수\n",
    "            이미지 결과를 보면 더 이해가 쉽기 때문에 아래 코드블럭 중 Check로 Markdown 표시를 한 곳에서 이미지를 확인하기를 추천!!!\n",
    "        weakref\n",
    "            순환 참조로 인해 생기는 메모리 누수 문제를 해결하기 위해 import된 weakref 객체에 대해 실제로 값을 출력할 때는 Variable처럼 weakref도 어떠한 기본 데이터타입을 감싸고 있는 형태이므로 기본 생성자를 통해 객체를 호출함과 동시에 output을 사용해 실제 결과값을 확인함\n",
    "        self.grad. 즉 역전파 시작 시 기존에는 ndarray 인스턴스를 받았으나 고차 미분을 가능하게 하기 위해 ndarray 인스턴스가 아닌 Variable 인스턴스를 받도록 설정\n",
    "        입력 파라미터에 create_graph 변수 추가. 역전파 1회 계산 후 역전파를 비활성 모드로 실행하게 만드는 파라미터\n",
    "        with using_config(name, value) 구문을 생성하여 역전파 설정을 통해 들여쓰기된 구문의 수행 여부를 판단\n",
    "    shape, ndim, size, dtype : numpy에 기본적으로 내장되어있는 메서드를 @property 데코레이터를 활용하여 바로 호출할 수 있도록 설정\n",
    "    __len__ : data의 길이 반환\n",
    "    __repr__ : print로 객체를 표현할 때 return할 값을 설정\n",
    "    __mul__ : 다른 객체 또는 데이터타입과의 multiply 기능 지원\n",
    "    reshape(self, *shape) : 만약에 가변인자로 들어오는 shape 값이 1개인 경우 그 값의 instance가 tuple or list일 때 shape[0]를 shape로 지정하고 그 외의 경우에는 myPackage.functions.reshape 함수를 사용하여 *shape의 값을 그대로 반영하여 reshape 진행\n",
    "    transpose : Variable 인스턴스에서 transpose 메서드를 호출했을 때, myPackage.functions에서 transpose 함수를 바로 호출할 수 있도록 설정\n",
    "    T : transpose를 바로 실행할 수 있도록 만든 @property function. @property 데코레이터를 사용하여 self 객체를 instance 변수로 바로 사용할 수 있도록 설정하였음\n",
    "    >> Update\n",
    "        sum : myPackage.functions.sum 함수를 호출하여 Variable 인스턴스에서 바로 sum 함수를 호출할 수 있도록 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, data, name = None):\n",
    "        if data is not None:\n",
    "            if not isinstance(data, np.ndarray):\n",
    "                raise TypeError(f'{type(data)} is not supported.')\n",
    "\n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        self.grad = None\n",
    "        self.creator = None\n",
    "        self.generation = 0\n",
    "\n",
    "    def cleargrad(self):\n",
    "        self.grad = None\n",
    "\n",
    "    def set_creator(self, func):\n",
    "        self.creator = func\n",
    "        self.generation = func.generation + 1\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "    @property\n",
    "    def ndim(self):\n",
    "        return self.data.ndim\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        return self.data.size\n",
    "\n",
    "    @property\n",
    "    def dtype(self):\n",
    "        return self.data.dtype\n",
    "\n",
    "    @property\n",
    "    def T(self):\n",
    "        return myPackage.functions.transpose(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        if self.data is None:\n",
    "            return \"variable(None)\"\n",
    "        p = str(self.data).replace('\\n', '\\n' + ' ' * 9)\n",
    "        return f\"variable({p}) from class's __repr__\"\n",
    "\n",
    "    def reshape(self, *shape):\n",
    "        if len(shape) == 1 and isinstance(shape[0], (tuple, list)):\n",
    "            shape = shape[0]\n",
    "        return myPackage.functions.reshape(self, shape)\n",
    "\n",
    "    def transpose(self):\n",
    "        return myPackage.functions.transpose(self)\n",
    "\n",
    "    def sum(self, axis=None, keepdims=False):\n",
    "        return myPackage.functions.sum(self, axis, keepdims)\n",
    "\n",
    "    def backward(self, retain_grad = False, create_graph = False):\n",
    "        if self.grad is None:\n",
    "            self.grad = Variable(np.ones_like(self.data))\n",
    "\n",
    "        funcs = []\n",
    "        seen_set = set()\n",
    "\n",
    "        def add_func(f):\n",
    "            if f not in seen_set:\n",
    "                funcs.append(f)\n",
    "                seen_set.add(f)\n",
    "                funcs.sort(key = lambda x: x.generation)\n",
    "\n",
    "        add_func(self.creator)\n",
    "\n",
    "        while funcs:\n",
    "            f = funcs.pop()\n",
    "            gys = [output().grad for output in f.outputs]\n",
    "\n",
    "            with using_config('enable_backprop', create_graph):\n",
    "                gxs = f.backward(*gys)\n",
    "                if not isinstance(gxs, tuple):\n",
    "                    gxs = (gxs,)\n",
    "\n",
    "                for x, gx in zip(f.inputs, gxs):\n",
    "                    if x.grad is None:\n",
    "                        x.grad = gx\n",
    "                    else:\n",
    "                        x.grad = x.grad + gx\n",
    "\n",
    "                    if x.creator is not None:\n",
    "                        add_func(x.creator)\n",
    "            \n",
    "            if not retain_grad:\n",
    "                for y in f.outputs:\n",
    "                    y().grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(np.array([[1, 2, 3], [4, 5, 6]]))\n",
    "y = F.sum(x, axis=0)\n",
    "y.backward()\n",
    "print(y) # Variable([5 7 9])\n",
    "print(x.grad) # Variable([[1 1 1], [1 1 1]])\n",
    "\n",
    "x = Variable(np.random.randn(2, 3, 4, 5))\n",
    "y = x.sum(keepdims=True)\n",
    "print(y.shape) # (1, 1, 1, 1)"
   ]
  },
  {
   "source": [
    "## 브로드캐스트 함수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1 2 3]\n [1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "# numpy 예제\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.broadcast_to(x, (2, 3))\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "## sum_to 함수 (myPackage.utils)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myPackage.utils import sum_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[5 7 9]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "y = sum_to(x, (1, 3))\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 6]\n [15]]\n"
     ]
    }
   ],
   "source": [
    "y = sum_to(x, (2, 1))\n",
    "print(y)"
   ]
  },
  {
   "source": [
    "## broadcast_to & sum_to (ver.myPackage)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myPackage.functions.py\n",
    "\n",
    "class BroadcastTo(Function):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        y = np.broadcast_to(x, self.shape)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        gx = sum_to(gy, self.x_shape)\n",
    "        return gx\n",
    "\n",
    "def broadcast_to(x, shape):\n",
    "    if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "    return BroadcastTo(shape)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myPackage.functions.py\n",
    "\n",
    "from myPackage import utils\n",
    "\n",
    "class SumTo(Function):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_shape = x.shape\n",
    "        y = utils.sum_to(x, self.shape)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        gx = broadcast_to(gy, self.x_shape)\n",
    "        return gx\n",
    "\n",
    "def sum_to(x, shape):\n",
    "    if x.shape == shape:\n",
    "        return as_variable(x)\n",
    "    return SumTo(shape)(x)"
   ]
  },
  {
   "source": [
    "## 브로드캐스트 대응"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11 12 13]\n"
     ]
    }
   ],
   "source": [
    "# numpy 예제\n",
    "x0 = np.array([1, 2, 3])\n",
    "x1 = np.array([10])\n",
    "y = x0 + x1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myPackage.core_complex.py\n",
    "\n",
    "class Add(Function):\n",
    "    \"\"\" class Add\n",
    "    Update : 텐서에 대한 add 함수 사용 시, x0, x1의 shape을 저장하게 함으로써 브로드캐스트가 되도록 설정하고, backprop 단계에서 gx0와 gx1의 grad 값을 그대로 사용하되 shape이 달라지는 경우 broadcast의 역전파에 대응되는 sum_to가 적용되어야 하므로 그에 대한 코드가 추가되었다.\n",
    "    \"\"\"\n",
    "    def forward(self, x0, x1):\n",
    "        self.x0_shape, self.x1_shape = x0.shape, x1.shape\n",
    "        y = x0 + x1\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        gx0, gx1 = gy, gy\n",
    "        if self.x0_shape != self.x1_shape:\n",
    "            gx0 = myPackage.functions.sum_to(gx0, self.x0_shape)\n",
    "            gx1 = myPackage.functions.sum_to(gx1, self.x1_shape)\n",
    "        return gx0, gx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "variable([11 12 13]) from class's __repr__\nvariable([1 1 1]) from class's __repr__\nvariable([3]) from class's __repr__\n"
     ]
    }
   ],
   "source": [
    "x0 = Variable(np.array([1, 2, 3]))\n",
    "x1 = Variable(np.array([10]))\n",
    "y = x0 + x1\n",
    "print(y)\n",
    "\n",
    "y.backward()\n",
    "print(x0.grad)\n",
    "print(x1.grad)"
   ]
  },
  {
   "source": [
    "## 행렬의 곱"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}