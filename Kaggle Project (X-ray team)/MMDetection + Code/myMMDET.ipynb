{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "medical-faculty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2021 NVIDIA Corporation\n",
      "Built on Thu_Jan_28_19:41:49_Pacific_Standard_Time_2021\n",
      "Cuda compilation tools, release 11.2, V11.2.142\n",
      "Build cuda_11.2.r11.2/compiler.29558016_0\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "effective-texture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (x86_64-posix-seh-rev0, Built by MinGW-W64 project) 8.1.0\n",
      "Copyright (C) 2018 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "correct-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "executive-charleston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "frequent-scale",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mmcv-full in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (1.2.6)\n",
      "Requirement already satisfied: Pillow in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmcv-full) (7.0.0)\n",
      "Requirement already satisfied: addict in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmcv-full) (2.4.0)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmcv-full) (5.4.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmcv-full) (1.19.2)\n",
      "Requirement already satisfied: yapf in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmcv-full) (0.30.0)\n",
      "Requirement already satisfied: opencv-python>=3 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmcv-full) (4.5.1.48)\n",
      "Requirement already satisfied: regex in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmcv-full) (2020.11.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install mmcv-full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "altered-decision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " C 드라이브의 볼륨에는 이름이 없습니다.\n",
      " 볼륨 일련 번호: F23A-5D86\n",
      "\n",
      " C:\\Xray\\mmdetection 디렉터리\n",
      "\n",
      "2021-02-20  오후 08:15    <DIR>          .\n",
      "2021-02-20  오후 08:15    <DIR>          ..\n",
      "2021-02-19  오전 11:54    <DIR>          .dev_scripts\n",
      "2021-02-19  오전 11:54    <DIR>          .github\n",
      "2021-02-19  오전 11:54             1,438 .gitignore\n",
      "2021-02-19  오전 11:54             1,176 .pre-commit-config.yaml\n",
      "2021-02-19  오전 11:54               152 .readthedocs.yml\n",
      "2021-02-20  오후 03:25    <DIR>          checkpoints\n",
      "2021-02-20  오후 03:55    <DIR>          configs\n",
      "2021-02-20  오후 08:15    <DIR>          data\n",
      "2021-02-19  오전 11:54    <DIR>          demo\n",
      "2021-02-19  오전 11:54    <DIR>          docker\n",
      "2021-02-19  오전 11:54    <DIR>          docs\n",
      "2021-02-19  오전 11:54            11,603 LICENSE\n",
      "2021-02-19  오후 12:01    <DIR>          mmdet\n",
      "2021-02-21  오후 08:57    <DIR>          mmdet.egg-info\n",
      "2021-02-19  오전 11:54               300 pytest.ini\n",
      "2021-02-19  오전 11:54             8,543 README.md\n",
      "2021-02-19  오전 11:54    <DIR>          requirements\n",
      "2021-02-19  오전 11:54               113 requirements.txt\n",
      "2021-02-19  오전 11:54    <DIR>          resources\n",
      "2021-02-19  오전 11:54               475 setup.cfg\n",
      "2021-02-19  오전 11:54             6,025 setup.py\n",
      "2021-02-19  오전 11:54    <DIR>          tests\n",
      "2021-02-19  오전 11:54    <DIR>          tools\n",
      "2021-02-20  오후 04:13    <DIR>          work_dirs\n",
      "               9개 파일              29,825 바이트\n",
      "              17개 디렉터리  306,676,551,680 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pediatric-elimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Xray\\\\mmdetection'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pointed-jonathan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] 지정된 파일을 찾을 수 없습니다: 'mmdetection'\n",
      "C:\\Xray\\mmdetection\n"
     ]
    }
   ],
   "source": [
    "%cd mmdetection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "graduate-rendering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Xray/mmdetection\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmdet==2.9.0) (3.3.4)\n",
      "Requirement already satisfied: mmpycocotools in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmdet==2.9.0) (12.0.3)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmdet==2.9.0) (1.19.2)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmdet==2.9.0) (1.15.0)\n",
      "Requirement already satisfied: terminaltables in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmdet==2.9.0) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from matplotlib->mmdet==2.9.0) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from matplotlib->mmdet==2.9.0) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from matplotlib->mmdet==2.9.0) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from matplotlib->mmdet==2.9.0) (7.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from matplotlib->mmdet==2.9.0) (0.10.0)\n",
      "Requirement already satisfied: cython>=0.27.3 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmpycocotools->mmdet==2.9.0) (0.29.21)\n",
      "Requirement already satisfied: setuptools>=18.0 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (from mmpycocotools->mmdet==2.9.0) (52.0.0.post20210125)\n",
      "Installing collected packages: mmdet\n",
      "  Attempting uninstall: mmdet\n",
      "    Found existing installation: mmdet 2.9.0\n",
      "    Uninstalling mmdet-2.9.0:\n",
      "      Successfully uninstalled mmdet-2.9.0\n",
      "  Running setup.py develop for mmdet\n",
      "Successfully installed mmdet\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "three-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow==7.0.0 in d:\\anaconda3\\envs\\kagglexray\\lib\\site-packages (7.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow==7.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "opening-compromise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "every-insertion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import mmdet\n",
    "print(mmdet.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hired-handy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2\n",
      "MSVC 192829337\n"
     ]
    }
   ],
   "source": [
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "level-retreat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!powershell \"(new-Object System.Net.WebClient).DownloadFile('http://download.openmmlab.com/mmdetection/v2.0/detectors/detectors_cascade_rcnn_r50_1x_coco/detectors_cascade_rcnn_r50_1x_coco-32a10ba0.pth', 'checkpoints/detectors_cascade_rcnn_r50_1x_coco-32a10ba0.pth')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cooperative-investor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'tail'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "'head'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n",
      "2021-02-22 05:35:12,480 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: win32\n",
      "Python: 3.8.5 (default, Sep  3 2020, 21:29:08) [MSC v.1916 64 bit (AMD64)]\n",
      "CUDA available: True\n",
      "GPU 0: GeForce RTX 3070\n",
      "CUDA_HOME: C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\n",
      "NVCC: Not Available\n",
      "GCC: n/a\n",
      "PyTorch: 1.7.1\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - C++ Version: 199711\n",
      "  - MSVC 192729112\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191125 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.6.0 (Git Hash 5ef631a030a6f73131c77892041042805a06064f)\n",
      "  - OpenMP 2019\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.0\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.0.4\n",
      "  - Magma 2.5.4\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -openmp:experimental -DNDEBUG -DUSE_FBGEMM -DUSE_VULKAN_WRAPPER, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.8.2\n",
      "OpenCV: 4.5.1\n",
      "MMCV: 1.2.6\n",
      "MMCV Compiler: MSVC 192829337\n",
      "MMCV CUDA Compiler: 11.2\n",
      "MMDetection: 2.9.0+292c6e6\n",
      "------------------------------------------------------------\n",
      "\n",
      "2021-02-22 05:35:12,947 - mmdet - INFO - Distributed training: False\n",
      "2021-02-22 05:35:13,400 - mmdet - INFO - Config:\n",
      "classes = ('Aortic enlargement', 'Ateletasis', 'Calcification', 'Cardiomegaly',\n",
      "           'Consolidation', 'ILD', 'Infiltration', 'Lung Opacity',\n",
      "           'Nodule/Mass', 'Other lesion', 'Pleural effusion',\n",
      "           'Pleural thickening', 'Pneumothorax', 'Pulmonary fibrosis')\n",
      "model = dict(\n",
      "    type='CascadeRCNN',\n",
      "    pretrained='torchvision://resnet101',\n",
      "    backbone=dict(\n",
      "        type='DetectoRS_ResNet',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=True,\n",
      "        style='pytorch',\n",
      "        conv_cfg=dict(type='ConvAWS'),\n",
      "        sac=dict(type='SAC', use_deform=True),\n",
      "        stage_with_sac=(False, True, True, True),\n",
      "        output_img=True,\n",
      "        dcn=dict(type='DCN', deformable_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, True, True, True)),\n",
      "    neck=dict(\n",
      "        type='RFP',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5,\n",
      "        rfp_steps=2,\n",
      "        aspp_out_channels=64,\n",
      "        aspp_dilations=(1, 3, 6, 1),\n",
      "        rfp_backbone=dict(\n",
      "            rfp_inplanes=256,\n",
      "            type='DetectoRS_ResNet',\n",
      "            depth=50,\n",
      "            num_stages=4,\n",
      "            out_indices=(0, 1, 2, 3),\n",
      "            frozen_stages=1,\n",
      "            norm_cfg=dict(type='BN', requires_grad=True),\n",
      "            norm_eval=True,\n",
      "            conv_cfg=dict(type='ConvAWS'),\n",
      "            sac=dict(type='SAC', use_deform=True),\n",
      "            stage_with_sac=(False, True, True, True),\n",
      "            pretrained='torchvision://resnet50',\n",
      "            style='pytorch')),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='CascadeRoIHead',\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[1, 0.5, 0.25],\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=14,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=14,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared2FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=14,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
      "        ]),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=0,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_across_levels=False,\n",
      "            nms_pre=2000,\n",
      "            nms_post=2000,\n",
      "            max_num=2000,\n",
      "            nms_thr=0.7,\n",
      "            min_bbox_size=0),\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    min_pos_iou=0.6,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    min_pos_iou=0.7,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_across_levels=False,\n",
      "            nms_pre=1000,\n",
      "            nms_post=1000,\n",
      "            max_num=1000,\n",
      "            nms_thr=0.7,\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'CustomDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1333, 800),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=1,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CustomDataset',\n",
      "        ann_file='data/coco/annotations/instances_train.json',\n",
      "        img_prefix='data/coco/train/',\n",
      "        classes=('Aortic enlargement', 'Ateletasis', 'Calcification',\n",
      "                 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration',\n",
      "                 'Lung Opacity', 'Nodule/Mass', 'Other lesion',\n",
      "                 'Pleural effusion', 'Pleural thickening', 'Pneumothorax',\n",
      "                 'Pulmonary fibrosis'),\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CustomDataset',\n",
      "        ann_file='data/coco/annotations/instances_val.json',\n",
      "        img_prefix='data/coco/val/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CustomDataset',\n",
      "        ann_file='data/coco/annotations/instances_val.json',\n",
      "        img_prefix='data/coco/val/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.005, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "total_epochs = 12\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "work_dir = 'work_dirs/detectors_cascade_rcnn_r50_1x_xray'\n",
      "gpu_ids = range(0, 1)\n",
      "\n",
      "D:\\Anaconda3\\envs\\kaggleXray\\lib\\site-packages\\mmcv\\utils\\misc.py:303: UserWarning: \"deformable_groups\" is deprecated in `DeformConv2d.__init__`, please use \"deform_groups\" instead\n",
      "  warnings.warn(\n",
      "2021-02-22 05:35:14,835 - mmdet - INFO - load model from: torchvision://resnet101\n",
      "2021-02-22 05:35:15,435 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer3.6.conv2.weight_diff, layer3.6.conv2.switch.weight, layer3.6.conv2.switch.bias, layer3.6.conv2.pre_context.weight, layer3.6.conv2.pre_context.bias, layer3.6.conv2.post_context.weight, layer3.6.conv2.post_context.bias, layer3.6.conv2.offset_s.weight, layer3.6.conv2.offset_s.bias, layer3.6.conv2.offset_l.weight, layer3.6.conv2.offset_l.bias, layer3.7.conv2.weight_diff, layer3.7.conv2.switch.weight, layer3.7.conv2.switch.bias, layer3.7.conv2.pre_context.weight, layer3.7.conv2.pre_context.bias, layer3.7.conv2.post_context.weight, layer3.7.conv2.post_context.bias, layer3.7.conv2.offset_s.weight, layer3.7.conv2.offset_s.bias, layer3.7.conv2.offset_l.weight, layer3.7.conv2.offset_l.bias, layer3.8.conv2.weight_diff, layer3.8.conv2.switch.weight, layer3.8.conv2.switch.bias, layer3.8.conv2.pre_context.weight, layer3.8.conv2.pre_context.bias, layer3.8.conv2.post_context.weight, layer3.8.conv2.post_context.bias, layer3.8.conv2.offset_s.weight, layer3.8.conv2.offset_s.bias, layer3.8.conv2.offset_l.weight, layer3.8.conv2.offset_l.bias, layer3.9.conv2.weight_diff, layer3.9.conv2.switch.weight, layer3.9.conv2.switch.bias, layer3.9.conv2.pre_context.weight, layer3.9.conv2.pre_context.bias, layer3.9.conv2.post_context.weight, layer3.9.conv2.post_context.bias, layer3.9.conv2.offset_s.weight, layer3.9.conv2.offset_s.bias, layer3.9.conv2.offset_l.weight, layer3.9.conv2.offset_l.bias, layer3.10.conv2.weight_diff, layer3.10.conv2.switch.weight, layer3.10.conv2.switch.bias, layer3.10.conv2.pre_context.weight, layer3.10.conv2.pre_context.bias, layer3.10.conv2.post_context.weight, layer3.10.conv2.post_context.bias, layer3.10.conv2.offset_s.weight, layer3.10.conv2.offset_s.bias, layer3.10.conv2.offset_l.weight, layer3.10.conv2.offset_l.bias, layer3.11.conv2.weight_diff, layer3.11.conv2.switch.weight, layer3.11.conv2.switch.bias, layer3.11.conv2.pre_context.weight, layer3.11.conv2.pre_context.bias, layer3.11.conv2.post_context.weight, layer3.11.conv2.post_context.bias, layer3.11.conv2.offset_s.weight, layer3.11.conv2.offset_s.bias, layer3.11.conv2.offset_l.weight, layer3.11.conv2.offset_l.bias, layer3.12.conv2.weight_diff, layer3.12.conv2.switch.weight, layer3.12.conv2.switch.bias, layer3.12.conv2.pre_context.weight, layer3.12.conv2.pre_context.bias, layer3.12.conv2.post_context.weight, layer3.12.conv2.post_context.bias, layer3.12.conv2.offset_s.weight, layer3.12.conv2.offset_s.bias, layer3.12.conv2.offset_l.weight, layer3.12.conv2.offset_l.bias, layer3.13.conv2.weight_diff, layer3.13.conv2.switch.weight, layer3.13.conv2.switch.bias, layer3.13.conv2.pre_context.weight, layer3.13.conv2.pre_context.bias, layer3.13.conv2.post_context.weight, layer3.13.conv2.post_context.bias, layer3.13.conv2.offset_s.weight, layer3.13.conv2.offset_s.bias, layer3.13.conv2.offset_l.weight, layer3.13.conv2.offset_l.bias, layer3.14.conv2.weight_diff, layer3.14.conv2.switch.weight, layer3.14.conv2.switch.bias, layer3.14.conv2.pre_context.weight, layer3.14.conv2.pre_context.bias, layer3.14.conv2.post_context.weight, layer3.14.conv2.post_context.bias, layer3.14.conv2.offset_s.weight, layer3.14.conv2.offset_s.bias, layer3.14.conv2.offset_l.weight, layer3.14.conv2.offset_l.bias, layer3.15.conv2.weight_diff, layer3.15.conv2.switch.weight, layer3.15.conv2.switch.bias, layer3.15.conv2.pre_context.weight, layer3.15.conv2.pre_context.bias, layer3.15.conv2.post_context.weight, layer3.15.conv2.post_context.bias, layer3.15.conv2.offset_s.weight, layer3.15.conv2.offset_s.bias, layer3.15.conv2.offset_l.weight, layer3.15.conv2.offset_l.bias, layer3.16.conv2.weight_diff, layer3.16.conv2.switch.weight, layer3.16.conv2.switch.bias, layer3.16.conv2.pre_context.weight, layer3.16.conv2.pre_context.bias, layer3.16.conv2.post_context.weight, layer3.16.conv2.post_context.bias, layer3.16.conv2.offset_s.weight, layer3.16.conv2.offset_s.bias, layer3.16.conv2.offset_l.weight, layer3.16.conv2.offset_l.bias, layer3.17.conv2.weight_diff, layer3.17.conv2.switch.weight, layer3.17.conv2.switch.bias, layer3.17.conv2.pre_context.weight, layer3.17.conv2.pre_context.bias, layer3.17.conv2.post_context.weight, layer3.17.conv2.post_context.bias, layer3.17.conv2.offset_s.weight, layer3.17.conv2.offset_s.bias, layer3.17.conv2.offset_l.weight, layer3.17.conv2.offset_l.bias, layer3.18.conv2.weight_diff, layer3.18.conv2.switch.weight, layer3.18.conv2.switch.bias, layer3.18.conv2.pre_context.weight, layer3.18.conv2.pre_context.bias, layer3.18.conv2.post_context.weight, layer3.18.conv2.post_context.bias, layer3.18.conv2.offset_s.weight, layer3.18.conv2.offset_s.bias, layer3.18.conv2.offset_l.weight, layer3.18.conv2.offset_l.bias, layer3.19.conv2.weight_diff, layer3.19.conv2.switch.weight, layer3.19.conv2.switch.bias, layer3.19.conv2.pre_context.weight, layer3.19.conv2.pre_context.bias, layer3.19.conv2.post_context.weight, layer3.19.conv2.post_context.bias, layer3.19.conv2.offset_s.weight, layer3.19.conv2.offset_s.bias, layer3.19.conv2.offset_l.weight, layer3.19.conv2.offset_l.bias, layer3.20.conv2.weight_diff, layer3.20.conv2.switch.weight, layer3.20.conv2.switch.bias, layer3.20.conv2.pre_context.weight, layer3.20.conv2.pre_context.bias, layer3.20.conv2.post_context.weight, layer3.20.conv2.post_context.bias, layer3.20.conv2.offset_s.weight, layer3.20.conv2.offset_s.bias, layer3.20.conv2.offset_l.weight, layer3.20.conv2.offset_l.bias, layer3.21.conv2.weight_diff, layer3.21.conv2.switch.weight, layer3.21.conv2.switch.bias, layer3.21.conv2.pre_context.weight, layer3.21.conv2.pre_context.bias, layer3.21.conv2.post_context.weight, layer3.21.conv2.post_context.bias, layer3.21.conv2.offset_s.weight, layer3.21.conv2.offset_s.bias, layer3.21.conv2.offset_l.weight, layer3.21.conv2.offset_l.bias, layer3.22.conv2.weight_diff, layer3.22.conv2.switch.weight, layer3.22.conv2.switch.bias, layer3.22.conv2.pre_context.weight, layer3.22.conv2.pre_context.bias, layer3.22.conv2.post_context.weight, layer3.22.conv2.post_context.bias, layer3.22.conv2.offset_s.weight, layer3.22.conv2.offset_s.bias, layer3.22.conv2.offset_l.weight, layer3.22.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
      "\n",
      "2021-02-22 05:35:15,814 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias\n",
      "\n",
      "missing keys in source state_dict: layer2.0.conv2.weight_diff, layer2.0.conv2.switch.weight, layer2.0.conv2.switch.bias, layer2.0.conv2.pre_context.weight, layer2.0.conv2.pre_context.bias, layer2.0.conv2.post_context.weight, layer2.0.conv2.post_context.bias, layer2.0.conv2.offset_s.weight, layer2.0.conv2.offset_s.bias, layer2.0.conv2.offset_l.weight, layer2.0.conv2.offset_l.bias, layer2.0.rfp_conv.weight, layer2.0.rfp_conv.bias, layer2.1.conv2.weight_diff, layer2.1.conv2.switch.weight, layer2.1.conv2.switch.bias, layer2.1.conv2.pre_context.weight, layer2.1.conv2.pre_context.bias, layer2.1.conv2.post_context.weight, layer2.1.conv2.post_context.bias, layer2.1.conv2.offset_s.weight, layer2.1.conv2.offset_s.bias, layer2.1.conv2.offset_l.weight, layer2.1.conv2.offset_l.bias, layer2.2.conv2.weight_diff, layer2.2.conv2.switch.weight, layer2.2.conv2.switch.bias, layer2.2.conv2.pre_context.weight, layer2.2.conv2.pre_context.bias, layer2.2.conv2.post_context.weight, layer2.2.conv2.post_context.bias, layer2.2.conv2.offset_s.weight, layer2.2.conv2.offset_s.bias, layer2.2.conv2.offset_l.weight, layer2.2.conv2.offset_l.bias, layer2.3.conv2.weight_diff, layer2.3.conv2.switch.weight, layer2.3.conv2.switch.bias, layer2.3.conv2.pre_context.weight, layer2.3.conv2.pre_context.bias, layer2.3.conv2.post_context.weight, layer2.3.conv2.post_context.bias, layer2.3.conv2.offset_s.weight, layer2.3.conv2.offset_s.bias, layer2.3.conv2.offset_l.weight, layer2.3.conv2.offset_l.bias, layer3.0.conv2.weight_diff, layer3.0.conv2.switch.weight, layer3.0.conv2.switch.bias, layer3.0.conv2.pre_context.weight, layer3.0.conv2.pre_context.bias, layer3.0.conv2.post_context.weight, layer3.0.conv2.post_context.bias, layer3.0.conv2.offset_s.weight, layer3.0.conv2.offset_s.bias, layer3.0.conv2.offset_l.weight, layer3.0.conv2.offset_l.bias, layer3.0.rfp_conv.weight, layer3.0.rfp_conv.bias, layer3.1.conv2.weight_diff, layer3.1.conv2.switch.weight, layer3.1.conv2.switch.bias, layer3.1.conv2.pre_context.weight, layer3.1.conv2.pre_context.bias, layer3.1.conv2.post_context.weight, layer3.1.conv2.post_context.bias, layer3.1.conv2.offset_s.weight, layer3.1.conv2.offset_s.bias, layer3.1.conv2.offset_l.weight, layer3.1.conv2.offset_l.bias, layer3.2.conv2.weight_diff, layer3.2.conv2.switch.weight, layer3.2.conv2.switch.bias, layer3.2.conv2.pre_context.weight, layer3.2.conv2.pre_context.bias, layer3.2.conv2.post_context.weight, layer3.2.conv2.post_context.bias, layer3.2.conv2.offset_s.weight, layer3.2.conv2.offset_s.bias, layer3.2.conv2.offset_l.weight, layer3.2.conv2.offset_l.bias, layer3.3.conv2.weight_diff, layer3.3.conv2.switch.weight, layer3.3.conv2.switch.bias, layer3.3.conv2.pre_context.weight, layer3.3.conv2.pre_context.bias, layer3.3.conv2.post_context.weight, layer3.3.conv2.post_context.bias, layer3.3.conv2.offset_s.weight, layer3.3.conv2.offset_s.bias, layer3.3.conv2.offset_l.weight, layer3.3.conv2.offset_l.bias, layer3.4.conv2.weight_diff, layer3.4.conv2.switch.weight, layer3.4.conv2.switch.bias, layer3.4.conv2.pre_context.weight, layer3.4.conv2.pre_context.bias, layer3.4.conv2.post_context.weight, layer3.4.conv2.post_context.bias, layer3.4.conv2.offset_s.weight, layer3.4.conv2.offset_s.bias, layer3.4.conv2.offset_l.weight, layer3.4.conv2.offset_l.bias, layer3.5.conv2.weight_diff, layer3.5.conv2.switch.weight, layer3.5.conv2.switch.bias, layer3.5.conv2.pre_context.weight, layer3.5.conv2.pre_context.bias, layer3.5.conv2.post_context.weight, layer3.5.conv2.post_context.bias, layer3.5.conv2.offset_s.weight, layer3.5.conv2.offset_s.bias, layer3.5.conv2.offset_l.weight, layer3.5.conv2.offset_l.bias, layer4.0.conv2.weight_diff, layer4.0.conv2.switch.weight, layer4.0.conv2.switch.bias, layer4.0.conv2.pre_context.weight, layer4.0.conv2.pre_context.bias, layer4.0.conv2.post_context.weight, layer4.0.conv2.post_context.bias, layer4.0.conv2.offset_s.weight, layer4.0.conv2.offset_s.bias, layer4.0.conv2.offset_l.weight, layer4.0.conv2.offset_l.bias, layer4.0.rfp_conv.weight, layer4.0.rfp_conv.bias, layer4.1.conv2.weight_diff, layer4.1.conv2.switch.weight, layer4.1.conv2.switch.bias, layer4.1.conv2.pre_context.weight, layer4.1.conv2.pre_context.bias, layer4.1.conv2.post_context.weight, layer4.1.conv2.post_context.bias, layer4.1.conv2.offset_s.weight, layer4.1.conv2.offset_s.bias, layer4.1.conv2.offset_l.weight, layer4.1.conv2.offset_l.bias, layer4.2.conv2.weight_diff, layer4.2.conv2.switch.weight, layer4.2.conv2.switch.bias, layer4.2.conv2.pre_context.weight, layer4.2.conv2.pre_context.bias, layer4.2.conv2.post_context.weight, layer4.2.conv2.post_context.bias, layer4.2.conv2.offset_s.weight, layer4.2.conv2.offset_s.bias, layer4.2.conv2.offset_l.weight, layer4.2.conv2.offset_l.bias\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/train.py\", line 188, in <module>\n",
      "    main()\n",
      "  File \"tools/train.py\", line 164, in main\n",
      "    datasets = [build_dataset(cfg.data.train)]\n",
      "  File \"c:\\xray\\mmdetection\\mmdet\\datasets\\builder.py\", line 71, in build_dataset\n",
      "    dataset = build_from_cfg(cfg, DATASETS, default_args)\n",
      "  File \"D:\\Anaconda3\\envs\\kaggleXray\\lib\\site-packages\\mmcv\\utils\\registry.py\", line 179, in build_from_cfg\n",
      "    return obj_cls(**args)\n",
      "  File \"c:\\xray\\mmdetection\\mmdet\\datasets\\custom.py\", line 88, in __init__\n",
      "    self.data_infos = self.load_annotations(self.ann_file)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"c:\\xray\\mmdetection\\mmdet\\datasets\\custom.py\", line 114, in load_annotations\n",
      "    ann_df = pd.read_csv(ann_file)\n",
      "  File \"D:\\Anaconda3\\envs\\kaggleXray\\lib\\site-packages\\pandas\\io\\parsers.py\", line 610, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"D:\\Anaconda3\\envs\\kaggleXray\\lib\\site-packages\\pandas\\io\\parsers.py\", line 468, in _read\n",
      "    return parser.read(nrows)\n",
      "  File \"D:\\Anaconda3\\envs\\kaggleXray\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1057, in read\n",
      "    index, columns, col_dict = self._engine.read(nrows)\n",
      "  File \"D:\\Anaconda3\\envs\\kaggleXray\\lib\\site-packages\\pandas\\io\\parsers.py\", line 2061, in read\n",
      "    data = self._reader.read(nrows)\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 756, in pandas._libs.parsers.TextReader.read\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 771, in pandas._libs.parsers.TextReader._read_low_memory\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 827, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 814, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"pandas\\_libs\\parsers.pyx\", line 1951, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python tools/train.py configs/xray/detectors_cascade_rcnn_r50_1x_xray.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-firmware",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-activity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instructional-jewelry",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
